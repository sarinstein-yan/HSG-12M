import os
import glob
import time
import pickle
from functools import partial
import numpy as np
import sympy as sp
import networkx as nx
import itertools as it
from joblib import Parallel, delayed
# from multiprocessing.pool import ThreadPool
import poly2graph as p2g
from typing import Sequence, Tuple, Dict, List, Any

__all__ = [
    "HSG_Generator",
]

class HSG_Generator:
    """
    A class to generate and manage datasets of Hamiltonian Spectral Graphs (HSG)
    derived from characteristic polynomials.

    It systematically samples polynomial classes based on parameters such as
    hopping range (D = p+q) and the number of energy bands (s). The generation
    process respects mathematical symmetries (e.g., z-reciprocity, where
    P(z) is equivalent to z^(p+q)P(1/z)) to avoid redundant or physically
    equivalent classes, ensuring a unique set of foundational polynomials.

    For each unique polynomial class, graph samples are generated by systematically
    varying two free complex coefficients (denoted as 'a' and 'b').
    For instance, coefficients might be varied from -10-5i to +10+5i, using
    a grid of real and imaginary values (e.g., 13 real and 7 imaginary steps,
    leading to (13*7)^2 = 8281 samples per class).

    The class provides methods to:
    1. Generate unique characteristic polynomial classes (`generate_char_poly_classes`).
    2. Create a parameter table for coefficient sweeps (`generate_ParamTable`).
    3. Generate spectral graph datasets for each class (`generate_dataset`).
    4. Filter and select subsets of these generated datasets to create specific
       dataset variants (e.g., HSG-one-band, HSG-12M) (`select_subset`).

    Attributes
    ----------
    z : sp.Symbol
        Symbol for the complex variable z (often representing exp(iK)).
    E : sp.Symbol
        Symbol for the energy variable E.
    hopping_ranges : List[int]
        List of hopping ranges (D values, where D = p+q) to generate polynomials for.
    params : Tuple[sp.Symbol, ...]
        Symbols used as free parameters in the polynomial construction (e.g., a, b).
    num_bands : List[int]
        List of number of energy bands (s values) to consider for the polynomials.
    n_jobs : int
        Number of parallel jobs to run for computationally intensive tasks
        (-1 uses all available cores).
    """

    def __init__(
        self,
        z: sp.Symbol,
        E: sp.Symbol,
        hopping_range: Sequence[int] | int,
        params: Sequence[sp.Symbol],
        num_bands: Sequence[int] = [1, 2, 3], # Default from LaTeX: 1 to 3 bands
        n_jobs: int = -1,
    ):
        """
        Initialize the HSG_Generator.

        Parameters
        ----------
        z : sp.Symbol
            Symbol for z in the polynomials, typically z = exp(iK).
        E : sp.Symbol
            Symbol for E (energy) in the polynomials.
        hopping_range : int or list of int
            Single D value or list of D values (total hopping range p+q)
            to generate polynomials for. The LaTeX example uses D from 4 to 6.
        params : Sequence[sp.Symbol]
            Sequence of parameter symbols (e.g., a, b) to be used as free coefficients.
            The LaTeX example uses two free coefficients.
        num_bands : Sequence[int], optional
            List of number of bands (s) to consider, by default [1, 2, 3].
        n_jobs : int, optional
            Number of parallel jobs for computations, by default -1 (use all cores).
        """
        # Ensure hopping ranges is a list
        if isinstance(hopping_range, int):
            self.hopping_ranges = [hopping_range]
        else:
            self.hopping_ranges = list(hopping_range)
        # Ensure num_bands is a list
        if isinstance(num_bands, int):
            self.num_bands = [num_bands]
        else:
            self.num_bands = list(num_bands)
        # Assign core attributes
        self.z = z
        self.E = E
        self.params = tuple(params)
        self.n_jobs = n_jobs
        # Validity check for parameters
        self.num_params = len(self.params)
        for D_val in self.hopping_ranges:
            assert D_val >= 2, f"hopping_range ({D_val}) must be >= 2"
            # D-2 refers to the number of available intermediate z exponents.
            assert self.num_params <= D_val - 2 if D_val > 2 else self.num_params == 0, \
                f"num_params (= {self.num_params}) must not exceed D-2 ({D_val-2 if D_val > 2 else 'N/A, D<=2 should have 0 params for this rule'})"


    @staticmethod
    def _one_poly(
        z: sp.Symbol,
        E: sp.Symbol,
        D: int, # Total hopping range, D = p+q
        params: Tuple[sp.Symbol, ...], # Free coefficients (e.g., a, b)
        b: int, # Number of bands (s in LaTeX)
        q: int, # Max positive z exponent in the base term (q_latex in p+q_latex)
        E_deg_list: Tuple[int, ...], # Exponents for E in additional terms
        param_pos: Tuple[int, ...], # z exponents where params are inserted
    ) -> Tuple[Tuple[int, ...], str, sp.Poly, Dict]:
        """
        Build a single characteristic polynomial expression, its Sympy Poly object,
        and metadata describing its construction parameters.

        The construction starts with a base polynomial of the form:
          P_base(z,E) = -E^s + z^(-p) + z^q
        where s is the number of bands (`b`), and p+q = D (total hopping range).
        Additional terms are then incorporated. These terms involve powers of E
        (up to E^(s-1)) associated with intermediate z-exponents (z^i where
        i is between -p+1 and q-1, excluding 0). Free parameters (coefficients like 'a', 'b')
        are assigned to some of these z^i or E^k * z^i terms.

        Parameters
        ----------
        z : sp.Symbol
            Symbol for the complex variable z.
        E : sp.Symbol
            Symbol for the energy variable E.
        D : int
            Total hopping range (p+q).
        params : Tuple[sp.Symbol]
            Symbols for the free coefficients to be included (e.g., a, b).
        b : int
            Number of bands (s in LaTeX notation, E^s is the leading energy term).
        q : int
            Maximum positive z exponent in the base term (z^q).
            The corresponding maximum negative exponent is z^(-p) where p = D-q.
        E_deg_list : Tuple[int]
            Tuple of exponents for E assigned to each intermediate z-degree.
            The length of this tuple is D-2. Each exponent k must be in {0,1,...,s-1}.
        param_pos : Tuple[int]
            Tuple of z exponents (from the intermediate degrees) at which the
            parameter symbols from `params` are inserted as coefficients.

        Returns
        -------
        final_key : tuple
            A canonical key (tuple of tuples) representing the polynomial structure,
            used for de-duplication (handles z-reciprocity).
        expr_str : str
            String representation of the expanded polynomial.
        poly : sp.Poly
            Sympy Poly object (typically over z, 1/z, E).
        meta : dict
            Dictionary containing metadata such as construction parameters,
            LaTeX representation, and symbols used.
        """
        # Compute complementary exponent range
        p = D - q
        z_degs = [d for d in range(-p + 1, q) if d != 0]

        # Start with the base polynomial -E^b + z^q + z^{-p}
        expr = -E**b + z**q + z**(-p)
        param_map = dict(zip(param_pos, params))

        # Add additional terms based on E_deg_list and parameter positions
        for z_deg, E_deg in zip(z_degs, E_deg_list):
            if E_deg > 0 and z_deg in param_map:
                expr += param_map[z_deg] * E**E_deg * z**z_deg
            elif E_deg > 0:
                expr += E**E_deg * z**z_deg
            elif z_deg in param_map:
                expr += param_map[z_deg] * z**z_deg

        # Expand, convert to Poly, and gather metadata
        expr = sp.expand(expr)
        poly = sp.Poly(expr, z, 1/z, E)

        meta = {
            'parameter_symbols': tuple(str(p) for p in params),
            'generator_symbols': tuple(str(g) for g in poly.gens),
            'latex': sp.latex(expr),
            'sympy_repr': sp.srepr(poly),
            'number_of_bands': b,
            'max_left_hopping': q,
            'max_right_hopping': p,
            # Add construction details to metadata for clarity
            'intermediate_z_degrees': tuple(z_degs),
            'E_deg_assignments': E_deg_list,
            'param_degree_placements': param_pos,
        }

        # Build de-duplication key and its reciprocal
        flags = [1 if d in param_pos else 0 for d in z_degs]
        key = list(zip(z_degs, E_deg_list, flags))
        key_reciprocal = [(-d, e, f) for (d, e, f) in reversed(key)]
        final_key = min(tuple(key), tuple(key_reciprocal))

        return final_key, str(expr), poly, meta

    def generate_char_poly_classes(
        self
    ) -> Tuple[List[str], List[Dict]]:
        """
        Generates a comprehensive list of unique characteristic polynomial classes.

        It iterates over specified hopping ranges (D = p+q), number of bands (s),
        divisions of D into p and q, assignments of E degrees to intermediate z terms,
        and placements of free parameter symbols (e.g., 'a', 'b').

        Uniqueness is ensured by a canonical keying system that accounts for
        z-reciprocity (i.e., a polynomial P(z) and its reciprocal P(1/z) often
        represent physically equivalent systems and map to the same class if their
        spectra are identical).

        The output (list of polynomial strings and their metadata) forms the basis
        for generating graph instances. For example, the HSG dataset construction
        methodology described involves generating 1401 unique classes (24 one-band,
        275 two-band, 1102 three-band) by varying hopping ranges from 4 to 6 and
        bands from 1 to 3.

        Returns
        -------
        all_exprs : List[str]
            List of unique polynomial expressions (as strings).
        all_metas : List[Dict]
            List of metadata dictionaries, each corresponding to a polynomial
            in `all_exprs`.
        """
        all_exprs = []  # accumulator for expression strings
        all_metas = []  # accumulator for corresponding metadata

        for D in self.hopping_ranges:
            # Assemble tasks for this D
            tasks = []
            for b in self.num_bands:
                for q in range(1, D):
                    p = D - q
                    degs = [d for d in range(-p + 1, q) if d != 0]
                    for E_deg_list in it.product(range(b), repeat=D-2):
                        for pos in it.combinations(degs, len(self.params)):
                            tasks.append((b, q, E_deg_list, pos))

            print(f"[Hopping range = {D}] raw samples: {len(tasks)}")
            build = partial(self._one_poly, self.z, self.E, D, self.params)

            # Parallel execution of polynomial construction
            results = Parallel(n_jobs=self.n_jobs, backend='loky')(
                delayed(build)(*t) for t in tasks
            )
            if not results:
                continue  # skip if no results

            # Unzip results and remove duplicates
            keys, expr_strs, polys, metas = zip(*results)
            keys_arr = np.asarray(keys)
            unique_keys, unique_indices = np.unique(
                keys_arr, return_index=True, axis=0
            )

            exprs = [expr_strs[i] for i in unique_indices]
            mlist = [metas[i] for i in unique_indices]
            print(f"[Hopping range = {D}] unique samples: {len(exprs)}")

            # Extend accumulators
            all_exprs.extend(exprs)
            all_metas.extend(mlist)

        return all_exprs, all_metas


    @staticmethod
    def _get_single_param_sweep_values(
        real_coeff_walk: List[float],
        imag_coeff_walk: List[float],
    ) -> np.ndarray:
        """
        Generate a grid of complex parameter values from real and imaginary walks.

        This method creates a grid of complex values by summing a real part
        (from `real_coeff_walk`) and an imaginary part (from `imag_coeff_walk`).
        Each coefficient is formed by summing the real part and the imaginary part
        (scaled by 1j).

        Parameters
        ----------
        real_coeff_walk : List[float]
            Sequence of real component values for coefficients.
        imag_coeff_walk : List[float]
            Sequence of imaginary component values (e.g., [0, 0.5, 1.0] for 0j, 0.5j, 1j).

        Returns
        -------
        np.ndarray
            Array of complex parameter values.
        """
        # Convert walks to numpy arrays
        real_vals = np.array(real_coeff_walk)
        imag_vals = np.array(imag_coeff_walk)
        if not np.iscomplex(imag_vals).all():
            imag_vals = 1j * imag_vals
            print("imag_coeff_walk converted to complex (1j * imag_vals)")
        # Sum real + imag parts to form complex parameter grid
        param_arr = real_vals[:, None] + imag_vals[None, :]
        return param_arr.ravel()


    @staticmethod
    def generate_ParamTable(
        save_dir: str,
        file_name: str,
        exprs: List[str],
        metas: List[Dict],
        real_coeff_walk: List[float],
        imag_coeff_walk: List[float],
    ) -> None:
        """
        Generate and save a parameter table defining the sweep ranges for free coefficients.

        For two free complex coefficients (e.g., 'a' and 'b' defined in HSG_Generator),
        this method creates a grid of value pairs. Each coefficient is formed by
        summing a real part (from `real_coeff_walk`) and an imaginary part
        (from `imag_coeff_walk`, scaled by 1j).

        For example, if `real_coeff_walk` has 13 values and `imag_coeff_walk` has 7
        imaginary components (e.g., steps for 0j to 5j), this results in 13*7 = 91
        complex values for one coefficient. If there are two such coefficients,
        this method generates all (91*91) = 8281 pairs.

        This parameter table (e.g., 'ParamTable.npz') is intended to be used by
        `generate_dataset` to produce multiple graph samples for each polynomial class.

        Parameters
        ----------
        save_dir : str
            Directory to save the parameter table.
        file_name : str
            Name of the output file (NPZ format).
        exprs : List[str]
            List of polynomial expressions (strings) to include in the table.
            These are the unique classes generated by `generate_char_poly_classes`.
        metas : List[Dict]
            List of metadata dictionaries, corresponding to each expression in `exprs`.
        real_coeff_walk : List[float]
            Sequence of real component values for coefficients.
        imag_coeff_walk : List[float]
            Sequence of imaginary component values (e.g., [0, 0.5, 1.0] for 0j, 0.5j, 1j).
            The method will multiply these by 1j.
        """

        single_param_sweep_values = HSG_Generator._get_single_param_sweep_values(
            real_coeff_walk,
            imag_coeff_walk,
        )
        
        # Generate all ordered pairs (param1_val, param2_val)
        # This assumes two free parameters, as per LaTeX (a,b)
        # If num_params in HSG_Generator is different, this needs generalization
        # For now, hardcoding for 2 parameters.
        if len(metas) > 0 and metas[0].get('parameter_symbols') and len(metas[0]['parameter_symbols']) == 2:
            p1_vals_mesh, p2_vals_mesh = np.meshgrid(single_param_sweep_values, single_param_sweep_values)
            param_value_pairs = np.asarray([p1_vals_mesh.ravel(), p2_vals_mesh.ravel()])
        elif len(metas) > 0 and metas[0].get('parameter_symbols') and len(metas[0]['parameter_symbols']) == 1:
            param_value_pairs = np.asarray([single_param_sweep_values.ravel()]) # Only one parameter
        elif not (len(metas) > 0 and metas[0].get('parameter_symbols')): # No parameters or inconsistent metadata
             param_value_pairs = np.array([]) # No parameter values
        else: # More than 2 params, not covered by example
            raise ValueError("Parameter generation for >2 free coefficients not explicitly defined by example.")

        os.makedirs(save_dir, exist_ok=True)
        if not file_name.endswith('.npz'):
            file_name += '.npz'
        
        np.savez(
            os.path.join(save_dir, file_name),
            polys=np.array(exprs, dtype=object),
            metas=np.array(metas, dtype=object),
            param_vals=param_value_pairs,
        )
        print(f"Parameter table saved to {os.path.join(save_dir, file_name)}")
        if param_value_pairs.ndim == 2:
            print(f"Generated {param_value_pairs.shape[1]} parameter combinations for {param_value_pairs.shape[0]} free coefficient(s).")
        elif param_value_pairs.ndim == 1 and param_value_pairs.size > 0 :
             print(f"Generated {param_value_pairs.shape[0]} parameter combinations for 1 free coefficient.")
        else:
             print("No parameter combinations generated (likely 0 free coefficients).")


    @staticmethod
    def generate_dataset(
        class_idx: int,
        class_data: str = "./ParamTable.npz",
        save_dir: str = "./raw",
        num_partition: int = 10,
        short_edge_threshold: int = 30,
    ) -> None:
        """
        Generate and save spectral graph data for a single polynomial class using a
        pre-defined parameter table.

        This method loads a specific polynomial expression (identified by `class_idx`)
        and its associated metadata from the `class_data_file` (e.g., 'ParamTable.npz').
        It retrieves the grid of parameter value pairs (e.g., for coefficients 'a' and 'b')
        also stored in this file. Typically, this grid contains numerous combinations,
        such as (13 real * 7 imag)^2 = 8281 pairs, for systematic exploration.

        For each pair of coefficient values, they are substituted into the polynomial.
        The `poly2graph.CharPolyClass.spectral_graph` method is then used to compute
        the corresponding spectral graph.

        To handle potentially large numbers of graph generations, the parameter sweep
        can be divided into `num_partitions` for processing. The results for each
        partition are temporarily saved and then consolidated into a single compressed
        NPZ file for the class (e.g., `class_{class_idx}.npz`) in `save_dir`.
        This final file contains all generated graphs for the class, their corresponding
        coefficient values, and the class metadata.

        Parameters
        ----------
        class_idx : int
            Index of the polynomial class in the `class_data_file` to process.
        class_data_file : str, optional
            Path to the NPZ file containing polynomial expressions, metadata, and
            parameter value sweeps (e.g., 'ParamTable.npz'), by default "./ParamTable.npz".
        save_dir : str, optional
            Directory to save the generated dataset for this class, by default "./raw_class_data".
        num_partitions : int, optional
            Number of partitions to split the parameter sweep into for processing, by default 10.
        short_edge_threshold : int, optional
            Threshold for `poly2graph`'s short edge detection, by default 30.
        """
        # Define working symbols and parameter dict
        k, z, E, a, b = sp.symbols('k z E a b')
        params = {a, b}

        # Load param table with all parameter combinations
        data = np.load(class_data, allow_pickle=True)
        polys = data['polys']       # array of expression strings
        metas = data['metas']       # array of metadata dicts
        param1_vals, param2_vals = data['param_vals']

        # Split parameter sweeps into partitions
        p1_parts = np.array_split(param1_vals, num_partition)
        p2_parts = np.array_split(param2_vals, num_partition)

        print(f"[Class {class_idx}]: {polys[class_idx]}")
        cp = p2g.CharPolyClass(polys[class_idx], k, z, E, params)
        os.makedirs(save_dir, exist_ok=True)

        batcher = Parallel()
        for i, (v1, v2) in enumerate(zip(p1_parts, p2_parts)):
            print(f"[Class {class_idx}] Partition {i} - computing...")
            t0 = time.perf_counter()
            graphs, _ = cp.spectral_graph(
                {a: v1, b: v2}, 
                short_edge_threshold=short_edge_threshold,
            )

            # Save pickled graphs and their parameter values
            out = os.path.join(save_dir, f'class_{class_idx}_part_{i}.npz')
            graphs_ser = batcher(
                delayed(pickle.dumps)(g) for g in graphs
            )
            np.savez_compressed(
                out,
                graphs_pickle=graphs_ser,
                a_vals=v1,
                b_vals=v2,
            )
            dt = (time.perf_counter() - t0) / 60
            print(
                f"[Class {class_idx}] Partition {i} saved → {out}"
                f" ({len(graphs_ser)} graphs, took {dt:.4f} min)"
            )
        
        # Combine all partitions into a single NPZ
        all_pickles = []
        for i in range(num_partition):
            d = np.load(
                os.path.join(save_dir, f'class_{class_idx}_part_{i}.npz'), 
                allow_pickle=True
                )
            # .tolist() because np.savez loads object arrays as dtype=object
            all_pickles.extend(d['graphs_pickle'].tolist())
            os.remove(os.path.join(save_dir, f'class_{class_idx}_part_{i}.npz'))

        out = os.path.join(save_dir, f'class_{class_idx}.npz')
        np.savez_compressed(
            out,
            graphs_pickle=np.array(all_pickles, dtype=object),
            y=class_idx,
            a_vals=param1_vals,
            b_vals=param2_vals,
            **metas[class_idx],
        )
        print(f"[Class {class_idx}] Combined dataset saved → {out}")


    # --- HSG-topology helper functions --- #
    @staticmethod
    def _simple_copy_with_multiplicity(g_multi: nx.MultiGraph):
        """Collapse a (multi)graph into a simple Graph, recording multiplicity."""
        if not g_multi.is_multigraph():
            return g_multi          # already simple, nothing to do

        g_simple = nx.Graph() if isinstance(g_multi, nx.MultiGraph) else nx.DiGraph()
        g_simple.add_nodes_from(g_multi.nodes(data=True))

        for u, v, _k, data in g_multi.edges(keys=True, data=True):
            if g_simple.has_edge(u, v):
                g_simple[u][v]["m"] += 1          # bump multiplicity
            else:
                g_simple.add_edge(u, v, **data, m=1)
        return g_simple

    @staticmethod
    def wl_hash_safe(g, iters=3):
        """WL hash that tolerates MultiGraphs by collapsing them first."""
        g_for_hash = HSG_Generator._simple_copy_with_multiplicity(g)
        return nx.weisfeiler_lehman_graph_hash(
            g_for_hash,
            iterations=iters,
            edge_attr="m"  # include multiplicity in the label
        )

    def unique_indices_by_hash(self, graphs):
        hashes = Parallel(n_jobs=self.n_jobs, batch_size=256)(
            delayed(HSG_Generator.wl_hash_safe)(g) for g in graphs
        )
        first_seen = {}
        for idx, h in enumerate(hashes):
            first_seen.setdefault(h, idx)
        return list(first_seen.values())

    @staticmethod
    def get_topology_mask(class_idx, data_dir='./raw'):
        path = os.path.join(data_dir, f"class_{class_idx}.npz")
        graphs_pickle = np.load(path, allow_pickle=True)["graphs_pickle"]
        graphs = [pickle.loads(g) for g in graphs_pickle]
        return HSG_Generator.unique_indices_by_hash(graphs)

    def generate_topology_mask(
        class_indices: Sequence[int] = range(1, 1401),
        data_dir: str = "./raw",
        save_dir: str = "./",
    ) -> None:
        """Generate a topology mask for a specific class and save it."""
        os.makedirs(save_dir, exist_ok=True)
        topology_masks = []
        for class_idx in class_indices:
            mask = HSG_Generator.get_topology_mask(class_idx, data_dir)
            topology_masks.append(mask)
        
        with open(os.path.join(save_dir, "HSG-topology-mask.pkl"), "wb") as f:
            pickle.dump(topology_masks, f)
        print(f"Topology masks saved to {os.path.join(save_dir, 'HSG-topology-mask.pkl')}")


    # --- General Subset Selection Functions --- #
    @staticmethod
    def filter_metas(
        metas: List[Dict],
        number_of_bands=None,
        max_left_hopping=None,
        max_right_hopping=None,
        intermediate_z_degrees=None,
        E_deg_assignments=None,
        param_degree_placements=None,
    ) -> List[int]:
        """Return the indices of *metas* that match *all* supplied criteria.

        Examples
        --------
        >>> idx = HSG_Generator.filter_metas(
        ...     metas,
        ...     number_of_bands=2,
        ...     max_left_hopping=3,
        ... )

        Any keyword found in ``criteria`` must also be a key of each metadata
        dict; the entry is retained only if ``meta[key] == value`` for *every*
        supplied *(key,value)* pair.  Passing no criteria returns ``range(len(metas))``.
        """
        filters = {
            'number_of_bands': number_of_bands,
            'max_left_hopping': max_left_hopping,
            'max_right_hopping': max_right_hopping,
            'intermediate_z_degrees': intermediate_z_degrees,
            'E_deg_assignments': E_deg_assignments,
            'param_degree_placements': param_degree_placements,
        }
        matched = []
        for i, m in enumerate(metas):
            if all(desired is None or m.get(key) == desired
                   for key, desired in filters.items()):
                matched.append(i)
        return matched

    def select_subset(
        self,
        metas: List[Dict],
        input_dir: str = "./raw",
        output_dir: str = "./subset",
        a_vals_filter: Sequence[float] | None = None,
        b_vals_filter: Sequence[float] | None = None,
        **class_filters: Any,
    ) -> str:
        """Assemble a study subset from pre‑generated ``class_{cid}.npz`` files.

        Parameters
        ----------
        metas : list[dict]
            The list returned by :py:meth:`generate_char_poly_classes` (or the
            loaded ``metas`` array from *ParamTable.npz*).
        input_dir : str, default ``"./raw"``
            Folder containing *class_{cid}.npz* archives.
        output_dir : str, default current directory
            Folder to which the combined subset is written.
        a_vals_filter, b_vals_filter : Sequence[float] | None
            Optional whitelist of parameter values.  If supplied, only graphs
            whose sampled ``a``/``b`` lie in the corresponding list are
            included.
        **class_filters
            Any keywords accepted by :py:meth:`filter_metas` to restrict which
            *classes* are loaded (e.g. ``number_of_bands=3``).

        Returns
        -------
        str
            Path to the *npz* file containing the subset.  The file name is
            constructed from the filtering options so that repeated calls do
            not overwrite each other.
        """
        # ---- pick classes
        cls_ids = self.filter_metas(metas, **class_filters)
        if not cls_ids:
            raise ValueError("No classes match the supplied filters.")

        combined_pickles: list = []
        combined_a: list = []
        combined_b: list = []
        combined_metas: list = []

        for cid in cls_ids:
            fpath = os.path.join(input_dir, f"class_{cid}.npz")
            if not os.path.exists(fpath):
                raise FileNotFoundError(f"Expected file not found: {fpath}")

            data = np.load(fpath, allow_pickle=True)
            pkl, av, bv = data["graphs_pickle"], data["a_vals"], data["b_vals"]
            mask = np.ones(len(av), dtype=bool)
            if a_vals_filter is not None:
                mask &= np.isin(av, a_vals_filter)
            if b_vals_filter is not None:
                mask &= np.isin(bv, b_vals_filter)

            combined_pickles.extend(pkl[mask].tolist())
            combined_a.extend(av[mask].tolist())
            combined_b.extend(bv[mask].tolist())
            combined_metas.extend([metas[cid]] * int(mask.sum()))

        # ---- file name summarising filters
        fname_parts = ["subset"]
        for k, v in class_filters.items():
            fname_parts.append(f"{k}-{v}")
        if a_vals_filter is not None:
            fname_parts.append("a-" + "_".join(map(str, a_vals_filter)))
        if b_vals_filter is not None:
            fname_parts.append("b-" + "_".join(map(str, b_vals_filter)))
        fname = "_".join(fname_parts) + ".npz"
        out_path = os.path.join(output_dir, fname)

        # ---- save
        np.savez_compressed(
            out_path,
            graphs_pickle=np.array(combined_pickles, dtype=object),
            a_vals=np.array(combined_a),
            b_vals=np.array(combined_b),
            metas=np.array(combined_metas, dtype=object),
        )
        return out_path